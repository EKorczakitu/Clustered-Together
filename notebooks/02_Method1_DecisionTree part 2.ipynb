{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97d16344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eaa7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Minimal, weighted CV pipeline using sklearn trees\n",
    "# - CV over (max_depth, min_leaf_weight in exposure units)\n",
    "# - CV over ccp_alpha from cost_complexity_pruning_path\n",
    "# - Final fit + test metrics\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# ---------- weighted metrics ----------\n",
    "def wmae(y, yhat, w):\n",
    "    w = np.asarray(w, float)\n",
    "    return (np.abs(y - yhat) * w).sum() / np.clip(w.sum(), 1e-12, None)\n",
    "\n",
    "def wrmse(y, yhat, w):\n",
    "    w = np.asarray(w, float)\n",
    "    return np.sqrt(((y - yhat)**2 * w).sum() / np.clip(w.sum(), 1e-12, None))\n",
    "\n",
    "def weighted_r2(y, yhat, w):\n",
    "    w = np.asarray(w, float)\n",
    "    ybar = (y * w).sum() / np.clip(w.sum(), 1e-12, None)\n",
    "    ss_res = ((y - yhat)**2 * w).sum()\n",
    "    ss_tot = ((y - ybar)**2 * w).sum()\n",
    "    return 1.0 - ss_res / ss_tot if ss_tot > 0 else 0.0\n",
    "\n",
    "\n",
    "# ---------- SAFE Poisson deviance on COUNTS ----------\n",
    "def poisson_deviance(y_counts, exposure, yhat_rate):\n",
    "    \"\"\"\n",
    "    Exposure-weighted Poisson deviance for counts.\n",
    "    Safe for zeros & negatives:\n",
    "      - clips predicted rate >= 0\n",
    "      - ignores impossible rows (exp<=0 & y>0)\n",
    "      - computes y*log(y/lam) only where y>0 (no np.where(log(0))).\n",
    "    \"\"\"\n",
    "    y   = np.asarray(y_counts,  float)\n",
    "    exp = np.asarray(exposure,  float)\n",
    "    r   = np.asarray(yhat_rate, float)\n",
    "\n",
    "    # Non-negative predicted rate\n",
    "    r = np.clip(r, 0.0, None)\n",
    "\n",
    "    # Drop impossible rows: positive counts with nonpositive exposure\n",
    "    bad = (exp <= 0) & (y > 0)\n",
    "    if np.any(bad):\n",
    "        y, exp, r = y[~bad], exp[~bad], r[~bad]\n",
    "\n",
    "    mu  = np.clip(r * exp, 1e-12, None)\n",
    "\n",
    "    # y * log(y/mu) only where y > 0\n",
    "    dev = 0.0\n",
    "    mask = y > 0\n",
    "    if np.any(mask):\n",
    "        dev += 2.0 * np.sum(y[mask] * (np.log(y[mask]) - np.log(mu[mask])) - (y[mask] - mu[mask]))\n",
    "    if np.any(~mask):\n",
    "        dev += 2.0 * np.sum(0 - (y[~mask] - mu[~mask]))  # when y=0, term reduces to 2*mu\n",
    "    return float(dev)\n",
    "\n",
    "def scaled_deviance(y_counts, exposure, yhat_rate):\n",
    "    D  = poisson_deviance(y_counts, exposure, yhat_rate)\n",
    "    df = max(len(np.asarray(y_counts)) - 1, 1)\n",
    "    return D / df\n",
    "\n",
    "\n",
    "# ---------- Calibration table (O/E by prediction bins) ----------\n",
    "def calibration_table(pred_rate, y_counts, exposure, n_bins=12):\n",
    "    pred_rate = np.asarray(pred_rate, float)\n",
    "    y_counts  = np.asarray(y_counts, float)\n",
    "    exposure  = np.asarray(exposure, float)\n",
    "\n",
    "    ok = exposure > 0\n",
    "    pred_rate, y_counts, exposure = pred_rate[ok], y_counts[ok], exposure[ok]\n",
    "\n",
    "    # bin by predicted rate (quantiles)\n",
    "    q = np.quantile(pred_rate, np.linspace(0, 1, n_bins + 1))\n",
    "    q = np.unique(q)\n",
    "    if q.size <= 2:\n",
    "        bins = np.zeros_like(pred_rate, int)\n",
    "    else:\n",
    "        bins = np.minimum(np.digitize(pred_rate, q[1:-1], right=True), q.size - 2)\n",
    "\n",
    "    df = pd.DataFrame({\"bin\": bins, \"y\": y_counts, \"exp\": exposure, \"pred\": pred_rate})\n",
    "\n",
    "    # expected counts = sum(pred_rate * exposure) per bin\n",
    "    agg = df.groupby(\"bin\").agg(\n",
    "        exposure=(\"exp\", \"sum\"),\n",
    "        observed=(\"y\", \"sum\")\n",
    "    ).reset_index()\n",
    "\n",
    "    expected = (\n",
    "        df.groupby(\"bin\").apply(lambda g: float(np.sum(g[\"pred\"].to_numpy(float) * g[\"exp\"].to_numpy(float))))\n",
    "    )\n",
    "    expected.index.name = None\n",
    "    expected = expected.reset_index(drop=True).rename(\"expected\")\n",
    "\n",
    "    calib = pd.concat([agg, expected], axis=1)\n",
    "    calib[\"OE\"] = calib[\"observed\"] / np.clip(calib[\"expected\"], 1e-12, None)\n",
    "    return calib[[\"bin\",\"exposure\",\"observed\",\"expected\",\"OE\"]]\n",
    "\n",
    "# ---------- Pearson over-dispersion ----------\n",
    "def pearson_overdispersion(y_counts, exposure, pred_rate):\n",
    "    y   = np.asarray(y_counts, float)\n",
    "    exp = np.asarray(exposure, float)\n",
    "    r   = np.asarray(pred_rate, float)\n",
    "    mu  = np.clip(r * exp, 1e-12, None)\n",
    "    chi2 = np.sum((y - mu)**2 / mu)\n",
    "    df   = max(len(y) - 1, 1)\n",
    "    return chi2 / df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe7d66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emil\\AppData\\Local\\Temp\\ipykernel_11408\\2909726594.py:37: RuntimeWarning: divide by zero encountered in log\n",
      "  term = np.where(y > 0, y * np.log(y / lam), 0.0) - (y - lam)\n",
      "C:\\Users\\Emil\\AppData\\Local\\Temp\\ipykernel_11408\\2909726594.py:37: RuntimeWarning: invalid value encountered in multiply\n",
      "  term = np.where(y > 0, y * np.log(y / lam), 0.0) - (y - lam)\n",
      "C:\\Users\\Emil\\AppData\\Local\\Temp\\ipykernel_11408\\2909726594.py:37: RuntimeWarning: divide by zero encountered in log\n",
      "  term = np.where(y > 0, y * np.log(y / lam), 0.0) - (y - lam)\n",
      "C:\\Users\\Emil\\AppData\\Local\\Temp\\ipykernel_11408\\2909726594.py:37: RuntimeWarning: invalid value encountered in multiply\n",
      "  term = np.where(y > 0, y * np.log(y / lam), 0.0) - (y - lam)\n",
      "C:\\Users\\Emil\\AppData\\Local\\Temp\\ipykernel_11408\\2909726594.py:37: RuntimeWarning: divide by zero encountered in log\n",
      "  term = np.where(y > 0, y * np.log(y / lam), 0.0) - (y - lam)\n",
      "C:\\Users\\Emil\\AppData\\Local\\Temp\\ipykernel_11408\\2909726594.py:37: RuntimeWarning: invalid value encountered in multiply\n",
      "  term = np.where(y > 0, y * np.log(y / lam), 0.0) - (y - lam)\n",
      "C:\\Users\\Emil\\AppData\\Local\\Temp\\ipykernel_11408\\2909726594.py:37: RuntimeWarning: divide by zero encountered in log\n",
      "  term = np.where(y > 0, y * np.log(y / lam), 0.0) - (y - lam)\n",
      "C:\\Users\\Emil\\AppData\\Local\\Temp\\ipykernel_11408\\2909726594.py:37: RuntimeWarning: invalid value encountered in multiply\n",
      "  term = np.where(y > 0, y * np.log(y / lam), 0.0) - (y - lam)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pre] depth=12, min_leaf_w=16.0 -> CV Dev=37737.585051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emil\\AppData\\Local\\Temp\\ipykernel_11408\\2909726594.py:37: RuntimeWarning: divide by zero encountered in log\n",
      "  term = np.where(y > 0, y * np.log(y / lam), 0.0) - (y - lam)\n",
      "C:\\Users\\Emil\\AppData\\Local\\Temp\\ipykernel_11408\\2909726594.py:37: RuntimeWarning: invalid value encountered in multiply\n",
      "  term = np.where(y > 0, y * np.log(y / lam), 0.0) - (y - lam)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mean_dev'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     61\u001b[39m         mean_dev = \u001b[38;5;28mfloat\u001b[39m(np.mean(fold_scores))\n\u001b[32m     62\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[pre] depth=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00md\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, min_leaf_w=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmlw\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -> CV Dev=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_dev\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m mean_dev < \u001b[43mbest_pre\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean_dev\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[32m     64\u001b[39m             best_pre = {\u001b[33m\"\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(d), \u001b[33m\"\u001b[39m\u001b[33mmin_leaf_weight\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(mlw), \u001b[33m\"\u001b[39m\u001b[33mmean_wmae\u001b[39m\u001b[33m\"\u001b[39m: mean_dev}\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mChosen pre-pruning:\u001b[39m\u001b[33m\"\u001b[39m, best_pre)\n",
      "\u001b[31mKeyError\u001b[39m: 'mean_dev'"
     ]
    }
   ],
   "source": [
    "# ---------- data ----------\n",
    "from preprocessing.preprocessing_utils import preprocess_for_tree\n",
    "\n",
    "train = pd.read_csv(\"../data/claims_train.csv\")\n",
    "test  = pd.read_csv(\"../data/claims_test.csv\")\n",
    "\n",
    "X_tr, y_tr_rate, w_tr = preprocess_for_tree(train)\n",
    "X_te, y_te_rate, w_te = preprocess_for_tree(test)\n",
    "\n",
    "# counts for deviance (optional)\n",
    "y_tr_cnt = (y_tr_rate * w_tr).to_numpy(float)\n",
    "y_te_cnt = (y_te_rate * w_te).to_numpy(float)\n",
    "\n",
    "# arrays\n",
    "X = X_tr.values.astype(np.float32)\n",
    "y = y_tr_rate.values.astype(np.float32)\n",
    "w = w_tr.values.astype(np.float32)\n",
    "\n",
    "X_test = X_te.values.astype(np.float32)\n",
    "y_test = y_te_rate.values.astype(np.float32)\n",
    "w_test = w_te.values.astype(np.float32)\n",
    "\n",
    "# quick sanity (optional)\n",
    "assert np.all(w > 0), \"Exposure must be strictly positive after cleaning.\"\n",
    "assert np.all(y >= 0), \"Rates must be non-negative.\"\n",
    "\n",
    "# ---------- hyperparams ----------\n",
    "DEPTH_GRID = [12, 14]\n",
    "LEAFW_GRID = [16.0, 18.0, 20.0]    # exposure units (sum of weights in a leaf >= this)\n",
    "K_FOLDS    = 5\n",
    "SEED       = 7\n",
    "MAX_ALPHA_POINTS = 30\n",
    "\n",
    "kf = KFold(n_splits=K_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# ============================================\n",
    "# 1) CV over (max_depth, min_leaf_weight) with weighted WMAE\n",
    "#    (convert exposure threshold -> min_weight_fraction_leaf per fold)\n",
    "# ============================================\n",
    "best_pre = {\"max_depth\": None, \"min_leaf_weight\": None, \"mean_dev\": np.inf}\n",
    "\n",
    "for d in DEPTH_GRID:\n",
    "    for mlw in LEAFW_GRID:\n",
    "        fold_scores = []\n",
    "        for tr_idx, va_idx in kf.split(X):\n",
    "            Xtr, ytr, wtr = X[tr_idx], y[tr_idx], w[tr_idx]\n",
    "            Xva, yva, wva = X[va_idx], y[va_idx], w[va_idx]\n",
    "\n",
    "            # convert exposure threshold to per-fold fraction\n",
    "            frac = float(mlw / np.clip(wtr.sum(), 1e-12, None))\n",
    "            frac = float(np.clip(frac, 0.0, 0.4999))  # sklearn requires < 0.5\n",
    "\n",
    "            model = DecisionTreeRegressor(\n",
    "                criterion=\"squared_error\",\n",
    "                splitter=\"best\",\n",
    "                max_depth=int(d),\n",
    "                min_weight_fraction_leaf=frac,\n",
    "                ccp_alpha=0.0,\n",
    "                random_state=SEED\n",
    "            )\n",
    "            model.fit(Xtr, ytr, sample_weight=wtr)\n",
    "            yhat = np.clip(model.predict(Xva), 0.0, None)  # non-negative rate\n",
    "            yva_cnt = yva * wva  # counts on validation fold\n",
    "            fold_scores.append(poisson_deviance(yva_cnt, wva, yhat))\n",
    "\n",
    "        mean_dev = float(np.mean(fold_scores))\n",
    "        print(f\"[pre] depth={d}, min_leaf_w={mlw:.1f} -> CV Dev={mean_dev:.6f}\")\n",
    "        if mean_dev < best_pre[\"mean_dev\"]:\n",
    "            best_pre = {\"max_depth\": int(d), \"min_leaf_weight\": float(mlw), \"mean_dev\": mean_dev}\n",
    "\n",
    "print(\"Chosen pre-pruning:\", best_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca2729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 2) Build compact α-grid from CCP path (on full train with chosen pre-caps)\n",
    "# ============================================\n",
    "frac_full = float(best_pre[\"min_leaf_weight\"] / np.clip(w.sum(), 1e-12, None))\n",
    "frac_full = float(np.clip(frac_full, 0.0, 0.4999))\n",
    "\n",
    "seed_tree = DecisionTreeRegressor(\n",
    "    criterion=\"squared_error\",\n",
    "    splitter=\"best\",\n",
    "    max_depth=best_pre[\"max_depth\"],\n",
    "    min_weight_fraction_leaf=frac_full,\n",
    "    random_state=SEED\n",
    ")\n",
    "seed_tree.fit(X, y, sample_weight=w)\n",
    "path = seed_tree.cost_complexity_pruning_path(X, y, sample_weight=w)\n",
    "\n",
    "alphas = np.unique(np.asarray(path.ccp_alphas, float))\n",
    "if alphas.size == 0:\n",
    "    alphas = np.array([0.0], float)\n",
    "if alphas[0] > 0.0:\n",
    "    alphas = np.insert(alphas, 0, 0.0)\n",
    "if alphas.size > MAX_ALPHA_POINTS:\n",
    "    qs = np.linspace(0, 1, MAX_ALPHA_POINTS)\n",
    "    alphas = np.unique(np.quantile(alphas, qs))\n",
    "\n",
    "print(f\"Alpha grid ({len(alphas)} points): first={alphas[0]:.3g}, last={alphas[-1]:.3g}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5d32c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen α via CV: {'alpha': 3.0369141184607657e-07, 'mean_wmae': 0.1817476217580259}\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 3) CV over α with same pre-pruning caps (weighted WMAE)\n",
    "# ============================================\n",
    "alpha_scores = np.zeros_like(alphas, dtype=float)\n",
    "\n",
    "for tr_idx, va_idx in kf.split(X):\n",
    "    Xtr, ytr, wtr = X[tr_idx], y[tr_idx], w[tr_idx]\n",
    "    Xva, yva, wva = X[va_idx], y[va_idx], w[va_idx]\n",
    "\n",
    "    frac_fold = float(best_pre[\"min_leaf_weight\"] / np.clip(wtr.sum(), 1e-12, None))\n",
    "    frac_fold = float(np.clip(frac_fold, 0.0, 0.4999))\n",
    "\n",
    "    for i, a in enumerate(alphas):\n",
    "        model = DecisionTreeRegressor(\n",
    "            criterion=\"squared_error\",\n",
    "            splitter=\"best\",\n",
    "            max_depth=best_pre[\"max_depth\"],\n",
    "            min_weight_fraction_leaf=frac_fold,\n",
    "            ccp_alpha=float(a),\n",
    "            random_state=SEED\n",
    "        )\n",
    "        model.fit(Xtr, ytr, sample_weight=wtr)\n",
    "        yhat = np.clip(model.predict(Xva), 0.0, None)\n",
    "        yva_cnt = yva * wva\n",
    "        alpha_scores[i] += poisson_deviance(yva_cnt, wva, yhat)\n",
    "\n",
    "alpha_scores /= K_FOLDS\n",
    "i_best = int(np.argmin(alpha_scores))\n",
    "best_alpha = float(alphas[i_best])\n",
    "print(\"Chosen α via CV:\", {\"alpha\": best_alpha, \"mean_dev\": float(alpha_scores[i_best])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da715f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST METRICS (final pruned) ===\n",
      "WMAE        : 0.1828435645410214\n",
      "WRMSE       : 0.7744725602915187\n",
      "Weighted R^2: 0.013614787368146919\n",
      "Poisson Dev.: 48444.46224273751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emil\\AppData\\Local\\Temp\\ipykernel_11408\\812682618.py:37: RuntimeWarning: divide by zero encountered in log\n",
      "  term = np.where(y > 0, y * np.log(y / lam), 0.0) - (y - lam)\n",
      "C:\\Users\\Emil\\AppData\\Local\\Temp\\ipykernel_11408\\812682618.py:37: RuntimeWarning: invalid value encountered in multiply\n",
      "  term = np.where(y > 0, y * np.log(y / lam), 0.0) - (y - lam)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 4) Final fit on ALL training + test evaluation\n",
    "# ============================================\n",
    "final = DecisionTreeRegressor(\n",
    "    criterion=\"squared_error\",\n",
    "    splitter=\"best\",\n",
    "    max_depth=best_pre[\"max_depth\"],\n",
    "    min_weight_fraction_leaf=frac_full,\n",
    "    ccp_alpha=best_alpha,\n",
    "    random_state=SEED\n",
    ")\n",
    "final.fit(X, y, sample_weight=w)\n",
    "\n",
    "yhat_te = np.clip(final.predict(X_test), 0.0, None)\n",
    "\n",
    "# Calibration\n",
    "calib = calibration_table(yhat_te, y_te_cnt, w_test, n_bins=12)\n",
    "print(\"\\nCalibration by predicted-rate bins (O/E):\")\n",
    "print(calib.to_string(index=False))\n",
    "\n",
    "# Dispersion\n",
    "pearson_phi = pearson_overdispersion(y_te_cnt, w_test, yhat_te)\n",
    "scaled_D    = scaled_deviance(y_te_cnt, w_test, yhat_te)\n",
    "\n",
    "print(\"\\nDispersion diagnostics:\")\n",
    "print(f\"Pearson over-dispersion (test): {pearson_phi:.3f}\")\n",
    "print(f\"Scaled Poisson deviance/df (test): {scaled_D:.3f}\")\n",
    "\n",
    "# Test metrics\n",
    "print(\"\\n=== TEST METRICS (final pruned) ===\")\n",
    "print(\"WMAE        :\", wmae(y_test, yhat_te, w_test))\n",
    "print(\"WRMSE       :\", wrmse(y_test, yhat_te, w_test))\n",
    "print(\"Weighted R^2:\", weighted_r2(y_test, yhat_te, w_test))\n",
    "print(\"Poisson Dev.:\", poisson_deviance(y_te_cnt, w_test, yhat_te))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
