{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# From-scratch WEIGHTED Regression Tree\n",
    "# (only stdlib + NumPy inside the method)\n",
    "# =========================\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "# -------- primary metric for selection/reporting --------\n",
    "def wmae(y, yhat, w):\n",
    "    w = np.asarray(w, float)\n",
    "    return (np.abs(y - yhat) * w).sum() / w.sum()\n",
    "\n",
    "# -------- small helpers --------\n",
    "def wmean(y, w):\n",
    "    w = np.asarray(w, float)\n",
    "    sw = w.sum()\n",
    "    return (y * w).sum() / sw if sw > 0 else 0.0\n",
    "\n",
    "def leaf_sse(y, w):\n",
    "    mu = wmean(y, w)\n",
    "    return ((y - mu) ** 2 * w).sum()\n",
    "\n",
    "def wrmse(y, yhat, w):\n",
    "    w = np.asarray(w, float)\n",
    "    return np.sqrt(((y - yhat)**2 * w).sum() / w.sum())\n",
    "\n",
    "def weighted_r2(y, yhat, w):\n",
    "    w = np.asarray(w, float)\n",
    "    ybar = (y * w).sum() / w.sum()\n",
    "    ss_res = ((y - yhat)**2 * w).sum()\n",
    "    ss_tot = ((y - ybar)**2 * w).sum()\n",
    "    return 1.0 - ss_res / ss_tot if ss_tot > 0 else 0.0\n",
    "\n",
    "def poisson_deviance(y_counts, exposure, yhat_rate):\n",
    "    \"\"\"\n",
    "    y_counts: observed claim counts (can be reconstructed as y_rate * exposure)\n",
    "    exposure: exposure weights (>=0)\n",
    "    yhat_rate: predicted claim rate\n",
    "    \"\"\"\n",
    "    y = np.asarray(y_counts, float)\n",
    "    exp = np.asarray(exposure, float)\n",
    "    lam = np.clip(yhat_rate, 1e-12, None) * exp  # Poisson mean = rate * exposure\n",
    "    term = np.where(y > 0, y * np.log(y / lam), 0.0) - (y - lam)\n",
    "    return 2.0 * term.sum()\n",
    "\n",
    "@dataclass\n",
    "class Node:\n",
    "    feature: Optional[int] = None\n",
    "    threshold: Optional[float] = None\n",
    "    left: Optional[\"Node\"] = None\n",
    "    right: Optional[\"Node\"] = None\n",
    "    value: Optional[float] = None  # prediction at leaf\n",
    "\n",
    "    def is_leaf(self) -> bool:\n",
    "        return self.value is not None\n",
    "\n",
    "class DecisionTreeRegressorScratch:\n",
    "    \"\"\"\n",
    "    Simple exposure-weighted regression tree for rates.\n",
    "    - Splits minimize weighted SSE (sum of leaf SSEs).\n",
    "    - Leaf prediction = exposure-weighted mean of y in the region.\n",
    "    - Pre-pruning via max_depth and min_leaf_weight (exposure units).\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth: Optional[int] = None, min_leaf_weight: float = 5.0):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_leaf_weight = float(min_leaf_weight)\n",
    "        self.root: Optional[Node] = None\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray, w: np.ndarray):\n",
    "        X = np.asarray(X, float)\n",
    "        y = np.asarray(y, float)\n",
    "        w = np.asarray(w, float)\n",
    "        self.root = self._build_tree(X, y, w, np.arange(X.shape[0]), depth=0)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        X = np.asarray(X, float)\n",
    "        return np.array([self._traverse(x, self.root) for x in X], float)\n",
    "\n",
    "    # ----- internal: build tree -----\n",
    "    def _build_tree(self, X, y, w, idx, depth) -> Node:\n",
    "        # stopping rules\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or \\\n",
    "           (w[idx].sum() < 2 * self.min_leaf_weight) or \\\n",
    "           np.allclose(y[idx], y[idx][0]):\n",
    "            return Node(value=wmean(y[idx], w[idx]))\n",
    "\n",
    "        feat, thr, L, R = self._best_split(X, y, w, idx)\n",
    "        if feat is None:\n",
    "            return Node(value=wmean(y[idx], w[idx]))\n",
    "\n",
    "        left = self._build_tree(X, y, w, L, depth+1)\n",
    "        right = self._build_tree(X, y, w, R, depth+1)\n",
    "        return Node(feature=feat, threshold=thr, left=left, right=right)\n",
    "\n",
    "    # ----- internal: best split -----\n",
    "    def _best_split(self, X, y, w, idx) -> Tuple[Optional[int], Optional[float], Optional[np.ndarray], Optional[np.ndarray]]:\n",
    "        best = (None, None, None, None, np.inf)\n",
    "        n, d = X.shape\n",
    "        for j in range(d):\n",
    "            xj = X[idx, j]\n",
    "            uniq = np.unique(xj)\n",
    "            if uniq.size <= 1:\n",
    "                continue\n",
    "            # thresholds: midpoints; for one-hot 0/1, just 0.5\n",
    "            if uniq.size == 2 and uniq.min() == 0.0 and uniq.max() == 1.0:\n",
    "                candidates = [0.5]\n",
    "            else:\n",
    "                u = np.unique(np.sort(xj))\n",
    "                candidates = (u[:-1] + u[1:]) / 2.0\n",
    "\n",
    "            for t in candidates:\n",
    "                Lmask = xj <= t\n",
    "                if not Lmask.any() or Lmask.all():\n",
    "                    continue\n",
    "                L = idx[Lmask]; R = idx[~Lmask]\n",
    "                # exposure-weighted minimum leaf size\n",
    "                if w[L].sum() < self.min_leaf_weight or w[R].sum() < self.min_leaf_weight:\n",
    "                    continue\n",
    "                sse = leaf_sse(y[L], w[L]) + leaf_sse(y[R], w[R])\n",
    "                if sse < best[4]:\n",
    "                    best = (j, t, L, R, sse)\n",
    "\n",
    "        return best[0], best[1], best[2], best[3]\n",
    "\n",
    "    # ----- internal: predict one -----\n",
    "    def _traverse(self, x, node: Node) -> float:\n",
    "        while not node.is_leaf():\n",
    "            node = node.left if x[node.feature] <= node.threshold else node.right\n",
    "        return node.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen caps: {'max_depth': 19, 'min_leaf_weight': 20.0, 'wmae': np.float64(0.18151267421363473)}\n",
      "\n",
      "Validation metrics (chosen caps):\n",
      " WMAE           : 0.18151267421363473\n",
      " WRMSE          : 0.7420427339046141\n",
      " Weighted R^2   : 0.008088772458327065\n",
      " Poisson Dev.   : 62097.86846094347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5516\\828182436.py:44: RuntimeWarning: divide by zero encountered in log\n",
      "  term = np.where(y > 0, y * np.log(y / lam), 0.0) - (y - lam)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5516\\828182436.py:44: RuntimeWarning: invalid value encountered in multiply\n",
      "  term = np.where(y > 0, y * np.log(y / lam), 0.0) - (y - lam)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics:\n",
      " WMAE           : 0.18274868062615726\n",
      " WRMSE          : 0.7753352886417393\n",
      " Weighted R^2   : 0.011416014677926745\n",
      " Poisson Dev.   : 74588.3451497409\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from preprocessing.preprocessing_utils import preprocess_for_tree\n",
    "\n",
    "train = pd.read_csv(\"../data/claims_train.csv\")\n",
    "test  = pd.read_csv(\"../data/claims_test.csv\")\n",
    "\n",
    "X_tr, y_tr_rate, w_tr = preprocess_for_tree(train)\n",
    "X_te, y_te_rate, w_te = preprocess_for_tree(test)\n",
    "\n",
    "# Reconstruct counts for Poisson deviance (aligned with X rows)\n",
    "y_tr_cnt = (y_tr_rate * w_tr).to_numpy(float)\n",
    "y_te_cnt = (y_te_rate * w_te).to_numpy(float)\n",
    "\n",
    "# Convert to NumPy\n",
    "X_np = X_tr.values.astype(float)\n",
    "y_np = y_tr_rate.values.astype(float)\n",
    "w_np = w_tr.values.astype(float)\n",
    "\n",
    "# Simple train/val split\n",
    "rng = np.random.default_rng(42)\n",
    "idx = np.arange(len(y_np))\n",
    "rng.shuffle(idx)\n",
    "cut = int(0.8 * len(idx))\n",
    "tr_idx, va_idx = idx[:cut], idx[cut:]\n",
    "\n",
    "X_tr_np, y_tr_np, w_tr_np = X_np[tr_idx], y_np[tr_idx], w_np[tr_idx]\n",
    "X_va_np, y_va_np, w_va_np = X_np[va_idx], y_np[va_idx], w_np[va_idx]\n",
    "y_tr_cnt_np, y_va_cnt_np = y_tr_cnt[tr_idx], y_tr_cnt[va_idx]  # counts for deviance\n",
    "\n",
    "# =============================\n",
    "# Tiny CV grid (WMAE for selection)\n",
    "# =============================\n",
    "depth_grid = [9, 11, 13, 15, 17, 19, 21]\n",
    "leafw_grid = [7.0, 9.0, 11.0, 13.0, 15.0, 20.0, 50.0]\n",
    "\n",
    "best = None\n",
    "for d in depth_grid:\n",
    "    for m in leafw_grid:\n",
    "        tree = DecisionTreeRegressorScratch(max_depth=d, min_leaf_weight=m).fit(X_tr_np, y_tr_np, w_tr_np)\n",
    "        yhat_va = tree.predict(X_va_np)\n",
    "        score = wmae(y_va_np, yhat_va, w_va_np)\n",
    "        if (best is None) or (score < best[\"wmae\"]):\n",
    "            best = {\"max_depth\": d, \"min_leaf_weight\": m, \"wmae\": score, \"model\": tree, \"yhat_va\": yhat_va}\n",
    "\n",
    "print(\"Chosen caps:\", {k: best[k] for k in [\"max_depth\",\"min_leaf_weight\",\"wmae\"]})\n",
    "\n",
    "# ---- Validation metrics for the chosen model ----\n",
    "yhat_va = best[\"yhat_va\"]\n",
    "print(\"\\nValidation metrics (chosen caps):\")\n",
    "print(\" WMAE           :\", wmae(y_va_np, yhat_va, w_va_np))\n",
    "print(\" WRMSE          :\", wrmse(y_va_np, yhat_va, w_va_np))\n",
    "print(\" Weighted R^2   :\", weighted_r2(y_va_np, yhat_va, w_va_np))\n",
    "print(\" Poisson Dev.   :\", poisson_deviance(y_va_cnt_np, w_va_np, yhat_va))\n",
    "\n",
    "# =============================\n",
    "# Final fit on ALL training data with chosen caps\n",
    "# =============================\n",
    "final_tree = DecisionTreeRegressorScratch(\n",
    "    max_depth=best[\"max_depth\"],\n",
    "    min_leaf_weight=best[\"min_leaf_weight\"]\n",
    ").fit(X_np, y_np, w_np)\n",
    "\n",
    "# =============================\n",
    "# Test evaluation (if labels exist)\n",
    "# =============================\n",
    "if X_te is not None and y_te_rate is not None:\n",
    "    X_te_np = X_te.values.astype(float)\n",
    "    y_te_np = y_te_rate.values.astype(float)\n",
    "    w_te_np = w_te.values.astype(float)\n",
    "    yhat_te = final_tree.predict(X_te_np)\n",
    "\n",
    "    print(\"\\nTest metrics:\")\n",
    "    print(\" WMAE           :\", wmae(y_te_np, yhat_te, w_te_np))\n",
    "    print(\" WRMSE          :\", wrmse(y_te_np, yhat_te, w_te_np))\n",
    "    print(\" Weighted R^2   :\", weighted_r2(y_te_np, yhat_te, w_te_np))\n",
    "    # reconstruct counts for test if not already:\n",
    "    y_te_cnt_np = (y_te_np * w_te_np).astype(float)\n",
    "    print(\" Poisson Dev.   :\", poisson_deviance(y_te_cnt_np, w_te_np, yhat_te))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
